---
title: "WA growth rates"
author: "Nicola Mueller"
date: '2020-02-05'
output:
  bookdown::html_document2: default
bibliography: library.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library("coda")
library("colorblindr") 
library(grid)
library(gridExtra)
library(ggtree)

path = "/Users/nmueller/Documents/github/hCoV-19_WA"

end_time = as.Date('2020-01-10')
# read in the mrsi file
mrsi = read.table(paste(path,'/results/mrsi.tsv',sep="/"), sep="\t", header=T)

mrsi$date = as.Date(mrsi$mrsi)

clusters = read.table(paste(path,'/results/cluster_size.tsv',sep="/"), sep="\t", header=T)

timeframename = c('samples until 2020-03-10', 'samples until 2020-03-24')

# dispersion parameter (for offspring distribution)
k = 0.3

# R from exponential growth: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1766383/pdf/rspb20063754.pdf
# R = 1+r/b
# set becomin uninfectious rate
becoming_uninf = 36.5

# translation to I from: https://academic.oup.com/mbe/article/34/11/2982/3952784
# I = (Ne * R *(1 + 1/k))/gen_time
# set the generation time
generation_time = 1/becoming_uninf

# reporting delay of cases after infection https://science.sciencemag.org/content/early/2020/03/24/science.abb3221
reporting_delay = 9
```

# Get the sampling counts from UW Virology

```{r smapling}
require(rvest)
system(paste("curl -fsSL http://depts.washington.edu/labmed/covid19/ >> ", path, "/results/sampling.json", sep=""))
tmp = readLines(paste(path, "/results/sampling.json", sep="")) # line with a warning
first = T
for (i in seq(1,length(tmp))){
  if (startsWith(tmp[[i]],"<script type=\"application/json\"")){
    tmp2 = strsplit(tmp[[i]], split='\\[')[[1]]
    for (j in seq(1,length(tmp2))){
      if (grepl("Date:",tmp2[[j]])){
        tmp3 = strsplit(tmp2[[j]], split=",")[[1]]
        for (k in seq(1,length(tmp3))){
          tmp4 = strsplit(gsub("\"","",tmp3[[k]]), split="<br />")[[1]]
          if (length(tmp4)==3){
            tmp4 = strsplit(tmp4, split="\\:\\s+")
            new.dat = data.frame(date = as.Date(tmp4[[1]][[2]]), count = as.numeric(tmp4[[2]][[2]]), detection=gsub(']','',tmp4[[3]][[2]]))
            if (first){
              testing = new.dat
              first = F
            }else{
              testing = rbind(testing, new.dat)
            }
          }
        }
      }
    }
    break;
  }
}

first = T
first.growth = T
first.intro = T
for (i in seq(1,length(mrsi$filename))){
  time_diff = mrsi[i,"date"]-end_time
  time = seq(0,as.numeric(time_diff),14)
  
  if (!startsWith( as.character(mrsi[i,"filename"]),"multibd")){
    # read in the log file
    t = read.table(paste(path,'/out/', mrsi[i,'filename'], '.log',sep=""), sep="\t", header=T)
    # take a 10% burnin
    t = t[-seq(1,length(t$posterior)/10),]
    # read in all the Ne's
    for (j in seq(1,length(time))){
      method = strsplit(as.character(mrsi[i,'filename']), split="_")[[1]][[2]]
      timeframe = timeframename[as.numeric(strsplit(as.character(mrsi[i,'filename']), split="_")[[1]][[3]])]
      name = paste('Ne',j,sep="")
      hpdInt = HPDinterval(exp(as.mcmc(t[,name])))
      hpdInt.m = HPDinterval(exp(as.mcmc(t[,name])), prob=0.5)
      
      new.dat = data.frame(time=mrsi[i,"date"]-time[j], 
                           Ne.mean=median(exp(t[,name])), Ne.lower=hpdInt[1,'lower'], Ne.upper=hpdInt[1,'upper'], 
                           Ne.ll=hpdInt.m[1,'lower'], Ne.uu=hpdInt.m[1,'upper'], 
                           method = method, timeframe=timeframe)
      if (first){
        dat = new.dat
        first = F
      }else{
        dat = rbind(dat, new.dat)
      }
    }
    
    # get all the growth rates
    average_over = 1
    for (j in seq(1,length(time)-average_over,1)){
      method = strsplit(as.character(mrsi[i,'filename']), split="_")[[1]][[2]]
      timeframe = timeframename[as.numeric(strsplit(as.character(mrsi[i,'filename']), split="_")[[1]][[3]])]
      
      name1 = paste('Ne',j,sep="")
      name2 = paste('Ne',j+average_over,sep="")
      
      values = (t[,name1]-t[,name2])/(time[j+average_over]-time[j])*365
      
      doubling = log(2)/values
      R = 1+values/becoming_uninf
      R[which(R<=0)] = 0
      hpdInt = HPDinterval(as.mcmc(values))
      hpdInt.5 = HPDinterval(as.mcmc(values), prob=0.5)
      hpdInt.doubling = HPDinterval(as.mcmc(doubling))
      hpdInt.R = HPDinterval(as.mcmc(R))
 
      new.dat = data.frame(time=mrsi[i,"date"]-time[j], 
                           growth.mean=median(values), growth.lower=hpdInt[1,'lower'], growth.upper=hpdInt[1,'upper'], 
                           growth.ll=hpdInt.5[1,'lower'], growth.uu=hpdInt.5[1,'upper'], 
                           doubling.mean=median(doubling), doubling.lower=hpdInt.doubling[1,'lower'], doubling.upper=hpdInt.doubling[1,'upper'], 
                           R.mean=median(R), R.lower=hpdInt.R[1,'lower'], R.upper=hpdInt.R[1,'upper'], 
                           method = method, timeframe=timeframe)
      
      new.dat = rbind(new.dat, data.frame(time=mrsi[i,"date"]-time[j+1] +0.01, 
                           growth.mean=median(values), growth.lower=hpdInt[1,'lower'], growth.upper=hpdInt[1,'upper'], 
                          growth.ll=hpdInt.5[1,'lower'], growth.uu=hpdInt.5[1,'upper'], 
                          doubling.mean=median(doubling), doubling.lower=hpdInt.doubling[1,'lower'], doubling.upper=hpdInt.doubling[1,'upper'], 
                           R.mean=median(R), R.lower=hpdInt.R[1,'lower'], R.upper=hpdInt.R[1,'upper'], 
                           method = method, timeframe=timeframe))
  
      if (first.growth){
        growth = new.dat
        first.growth = F
      }else{
        growth = rbind(growth, new.dat)
      }
    }
  
    
  }
}

levels(dat$method) <- c("correlated Ne's", "uncorrelated Ne's", "correlated Ne trajectories")
dat$method <- factor(dat$method, levels =c("correlated Ne's", "correlated Ne trajectories", "uncorrelated Ne's"))

levels(growth$method) <- c("correlated Ne's", "uncorrelated Ne's", "correlated Ne trajectories")
growth$method <- factor(growth$method, levels =c("correlated Ne's", "correlated Ne trajectories", "uncorrelated Ne's"))


# compute the growth rates from testing
positive = testing[which(testing$detection=="Positive"),]
average_over = 7
for (i in seq(2,length(positive$date)-average_over, 1)){
  growt_val = 0
  for (j in seq(1,average_over)){
    growt_val = growt_val + log(positive[i+j,"count"]/positive[i+j-1,"count"])/(1/366)
  }
  growt_val = growt_val/average_over
  new.dat = data.frame(time=positive[i,"date"], growth=growt_val)
  new.dat = rbind(new.dat,data.frame(time=positive[i,"date"]+1-0.001, growth=growt_val))
  if (i==2){
    growth.testing = new.dat
  }else{
    growth.testing = rbind(growth.testing, new.dat)
  }
}

# read in the mrsi file
first = T
for (i in seq(1,length(mrsi$filename))){
  time_diff = mrsi[i,"date"]-end_time
  time = seq(0,as.numeric(time_diff),14)
  
  if (startsWith( as.character(mrsi[i,"filename"]),"multibd")){
    # read in the log file
    t = read.table(paste(path,'/out/', mrsi[i,'filename'], '.log',sep=""), sep="\t", header=T)
    # take a 10% burnin
    t = t[-seq(1,length(t$posterior)/10),]
    # read in all the Ne's
    for (j in seq(1,length(time))){
      method = strsplit(as.character(mrsi[i,'filename']), split="_")[[1]][[2]]
      timeframe = timeframename[as.numeric(strsplit(as.character(mrsi[i,'filename']), split="_")[[1]][[3]])]
      name = paste('logReproductiveNumber',length(time)-j+1,sep="")
      name2 = paste('samplingProportion',length(time)-j+1,sep="")
      
      hpdInt = HPDinterval(as.mcmc(t[,name]))
      hpdInt.samp = HPDinterval(as.mcmc(t[,name2]))
      
      new.dat = data.frame(time=mrsi[i,"date"]-time[j], 
                           Ne.mean=median(t[,name]), Ne.lower=hpdInt[1,'lower'], Ne.upper=hpdInt[1,'upper'], 
                           samp.mean=median(t[,name2]), samp.lower=hpdInt.samp[1,'lower'], samp.upper=hpdInt.samp[1,'upper'], 
                           method = method, timeframe=timeframe)
      new.dat = rbind(new.dat, data.frame(time=mrsi[i,"date"]-time[j]-14+0.001, 
                       Ne.mean=median(t[,name]), Ne.lower=hpdInt[1,'lower'], Ne.upper=hpdInt[1,'upper'], 
                       samp.mean=median(t[,name2]), samp.lower=hpdInt.samp[1,'lower'], samp.upper=hpdInt.samp[1,'upper'], 
                       method = method, timeframe=timeframe))

      if (first){
        dat.bdsky = new.dat
        first = F
      }else{
        dat.bdsky = rbind(dat.bdsky, new.dat)
      }
    }
  }
}


```


# Skygrid analysis


```{r skyline}

```

# comparison between number of samples and the effective population sizes.

```{r sampling_coal}
transform = 50
p = ggplot(dat[which(dat$method=="correlated Ne's" & dat$timeframe=="samples until 2020-03-24"),]) + 
  # geom_line(aes(x=time, y=Ne.mean*transform, color=timeframe)) +
  geom_histogram(data=testing[which(testing$detection=="Positive"),], aes(x=date-reporting_delay,y=count), sta="identity")+
  geom_ribbon(aes(x=time, ymin=Ne.lower*transform, ymax=Ne.upper*transform, fill=timeframe), alpha=0.2)+
  geom_ribbon(aes(x=time, ymin=Ne.ll*transform, ymax=Ne.uu*transform, fill=timeframe), alpha=0.4)+
  scale_x_date(limits=c(as.Date('2020-01-31'), max(mrsi$date)))  +
  scale_color_OkabeIto()+
  scale_fill_OkabeIto()+
  scale_color_manual(name="data source", values=c("#56B4E9"))+
  scale_fill_manual(name="data source", values=c("#56B4E9"))+
  theme_minimal() +
  theme(legend.position = "none")  +
    scale_y_continuous(sec.axis = sec_axis(~ 1/transform*., name = "effective population size")) +

  coord_cartesian(ylim=c(0.01,400))
  
plot(p)

ggsave(plot=p, file=paste(path, 'figures/coal_skygrid_testing.png', sep='/'), height=3,width=9)
```


```{r skyline_other}
p = ggplot(dat) + geom_line(aes(x=time, y=Ne.mean, color=timeframe)) +
  geom_ribbon(aes(x=time, ymin=Ne.lower, ymax=Ne.upper, fill=timeframe), alpha=0.2)+
  facet_wrap(method~., ncol=1) +
  scale_x_date(limits=c(as.Date('2020-01-25'), max(mrsi$date)))  +
  scale_color_OkabeIto()+
  scale_fill_OkabeIto()+
  scale_y_continuous(breaks=seq(-6.9078,6.9078,2.3026), labels=c(0.001,0.010,0.1,1,10,100,1000),sec.axis = sec_axis(~ .,breaks=seq(-6.9078,6.9078,2.3026), labels=c(0.001,0.010,0.1,1,10,100,1000), name = "Ne")) +
  theme_minimal() +
  theme(legend.position = "none") + 
  coord_cartesian(ylim=c(-6.9078,6.9078))
plot(p)

ggsave(plot=p, file=paste(path, 'figures/skygrid.pdf', sep='/'), height=5,width=9)

```

# Plot the lineages through time for each introduction

```{r ltt}

filename = paste('multicoal_skygrid_',length(timeframename), sep="")

# read in the log file 
t = read.table(paste(path,'/out/', filename, '.log',sep=""), sep="\t", header=T)
# take a 10% burnin
t = t[-seq(1,length(t$posterior)/10),]

# get all the intro times
indices = which(clusters$filename==filename)

# read in the ltt values
ltt = read.table(paste(path,'/results/ltt_mean.tsv',sep=""), sep="\t", header=T)

ltt.clusters = clusters[which(clusters$filename==filename),]
c = 1;
current_max = 0;
plot_offset = 5;

first = T
first.rep = T

for (j in seq(2,length(ltt))){
  # get the offset in days 
  name = paste('Tree.', gsub("X","",labels(ltt)[[2]][j]), '.trueHeight',sep='')
  name2 = gsub("trueHeight","height", name) 
  offset  = round((t[1,name]-t[1,name2])*365)
  
  max_val = max(ltt[,j])
  
  

  for (k in seq(1,length(ltt$day))){
    new.dat = data.frame(time = mrsi[which(mrsi$filename==filename), "date"] - offset -ltt[k,"day"],
                         val = ltt[k,j], val_offset = current_max + max_val/2, cluster = as.numeric(gsub("X","",labels(ltt)[[2]][j])))
    
    if (first){
      ltt.dat = new.dat
      first = F
    }else{
      ltt.dat = rbind(ltt.dat, new.dat)
    }
  }
  
  
  
  current_max = current_max + max_val + plot_offset
}



ltt.dat$origin = "Europe"

ltt.dat[which(ltt.dat$cluster==ltt.dat[which.max(ltt.dat$val),"cluster"]), "origin"] = "China"

p = ggplot(ltt.dat) + geom_ribbon(aes(x=time, ymin=val_offset-val/2, ymax=val_offset+val/2, group=cluster, fill=origin)) +
  scale_x_date(limits=c(as.Date('2020-02-01'), max(mrsi$date)))  +
  theme_minimal() +
  geom_vline(xintercept=as.Date('2020-03-05'))+
  geom_vline(xintercept=as.Date('2020-03-13'))+
  geom_vline(xintercept=as.Date('2020-03-23'))+
  scale_fill_manual(values=c("#aa381e", "#003399"))+
  ggtitle('Lineages through time of different local outbreak clusters') +
  xlab("")
plot(p)
ggsave(plot=p, file=paste(path, 'figures/coal_ltt.png', sep='/'), height=5,width=9)

uni_times = unique(ltt.dat$time)
ltt.dat$rel = 0

ltt.dat$min_val = ltt.dat$val
ltt.dat[which(ltt.dat$min_val<1),"min_val"] = 0
for (i in seq(1,length(uni_times))){
  ind = which(ltt.dat$time==uni_times[i])
  ltt.dat[ind,"rel"] = ltt.dat[ind, "min_val"]/sum(ltt.dat[ind, "min_val"])
}

ltt.dat[which(ltt.dat$rel==0), "rel"] =0.000001
p = ggplot(ltt.dat[which(!is.nan(ltt.dat$rel)),]) + 
  geom_area(aes(x=time,y=rel,fill=origin, group=cluster),position="stack", stat="identity") +
  scale_fill_manual(values=c("#aa381e", "#003399")) +
  theme_minimal()

plot(p)

```

```{r growth_rates}
p_coal_growth_supp = ggplot(growth) + 
  geom_path(aes(x=time, y=growth.mean, color=timeframe)) +
  geom_ribbon(aes(x=time, ymin=growth.lower, ymax=growth.upper, fill=timeframe), alpha=0.2) +
  geom_path(data=growth.testing, aes(x=time, y=growth, color="testing")) +
  facet_wrap(method~., ncol=1) +
  scale_x_date(limits=c(as.Date('2020-01-25'), max(mrsi$date)))  +
  coord_cartesian(ylim=c(-150,300))+
  scale_color_OkabeIto()+
  scale_fill_OkabeIto()+
  theme_minimal()
doubling_labels = c(-1,-2,-6,6,2,1)
p_coal_growth_supp <- p_coal_growth_supp + scale_y_continuous(sec.axis = sec_axis(~ .,breaks=round(log(2)/doubling_labels*365), labels=doubling_labels, name = "doubling times in days"))
ggsave(plot=p_coal_growth_supp, file=paste(path, 'figures/coal_growth_supp.pdf', sep='/'), height=5,width=9)





p_coal_growth = ggplot(growth[which(growth$method=="correlated Ne's" & growth$timeframe=="samples until 2020-03-24"),]) + 
  # geom_line(aes(x=time, y=growth.mean, color="genetic data")) +
  geom_ribbon(aes(x=time, ymin=growth.lower, ymax=growth.upper), fill="#56B4E9", alpha=0.2) +
  geom_ribbon(aes(x=time, ymin=growth.ll, ymax=growth.uu), fill="#56B4E9", alpha=0.4) +
  geom_path(data=growth.testing, aes(x=time-reporting_delay, y=growth, color="confirmed positive tests")) +
  scale_x_date(limits=c(as.Date('2020-01-25'), max(mrsi$date)))  +
  coord_cartesian(ylim=c(-100,300))+
  scale_color_manual(name="data source", values=c("#D55E00", "#56B4E9"))+
  xlab("")+
  theme_minimal()
doubling_labels = c(-1,-2,-6,6,2,1)
p_coal_growth <- p_coal_growth + scale_y_continuous(sec.axis = sec_axis(~ .,breaks=round(log(2)/doubling_labels*365), labels=doubling_labels, name = "doubling times in days")) + ylab("growth rate per year")

plot(p_coal_growth)
ggsave(plot=p_coal_growth, file=paste(path, 'figures/coal_growth.png', sep='/'), height=3,width=9)


```

```{r R0}

p_R0 = ggplot(growth[which(growth$method=="correlated Ne's" & growth$timeframe=="samples until 2020-03-24"),]) + 
  geom_path(aes(x=time, y=R.mean, color="coalesent skyline")) +
  geom_ribbon(aes(x=time, ymin=R.lower, ymax=R.upper, fill="coalesent skyline"), alpha=0.2) +
  geom_line(data=dat.bdsky[which(dat.bdsky$timeframe=="samples until 2020-03-24"),],aes(x=time, y=exp(Ne.mean), color="birth-death skyline")) +
  geom_ribbon(data=dat.bdsky[which(dat.bdsky$timeframe=="samples until 2020-03-24"),], aes(x=time, ymin=exp(Ne.lower), ymax=exp(Ne.upper), fill="birth-death skyline"), alpha=0.2)+
  ylab("Effective Reproduction Number")+
  scale_x_date(limits=c(as.Date('2020-01-25'), max(mrsi$date)))  +
  coord_cartesian(ylim=c(0,7.5))+
  geom_vline(xintercept=as.Date('2020-03-05'))+
  geom_vline(xintercept=as.Date('2020-03-13'))+
  geom_vline(xintercept=as.Date('2020-03-23'))+
  scale_color_manual(name="method", values=c("#F0E442", "#56B4E9"))+
  scale_fill_manual(name="method", values=c("#F0E442", "#56B4E9"))+
  theme_minimal()
plot(p_R0)

ggsave(plot=p_R0, file=paste(path, 'figures/R0.png', sep='/'), height=3,width=9)


```

```{r sampling_proportions}

p_R0_bdsky = 
  ggplot(dat.bdsky[which(dat.bdsky$timeframe=="samples until 2020-03-24"),]) + 
  geom_line(aes(x=time, y=exp(Ne.mean), color=timeframe)) +
  geom_ribbon(aes(x=time, ymin=exp(Ne.lower), ymax=exp(Ne.upper), fill=timeframe), alpha=0.2)+
  scale_x_date(limits=c(as.Date('2020-01-25'), max(mrsi$date)))  +
  geom_vline(xintercept=as.Date('2020-03-05'))+
  geom_vline(xintercept=as.Date('2020-03-13'))+
  geom_vline(xintercept=as.Date('2020-03-23'))+
  scale_color_manual(name="data source", values=c("#D55E00", "#56B4E9"))+
  facet_wrap(timeframe~., ncol=1)+
  theme_minimal() +
  theme(legend.position = "none")
  coord_cartesian(ylim=c(0,7.5))
plot(p_R0_bdsky)

ggsave(plot=p, file=paste(path, 'figures/bdsky_skygrid.pdf', sep='/'), height=5,width=9)

p = ggplot(dat.bdsky) + geom_line(aes(x=time, y=exp(samp.mean), color=timeframe)) +
  geom_ribbon(aes(x=time, ymin=exp(samp.lower), ymax=exp(samp.upper), fill=timeframe), alpha=0.2)+
  scale_x_date(limits=c(as.Date('2020-01-25'), max(mrsi$date)))  +
  geom_vline(xintercept=as.Date('2020-03-05'))+
  geom_vline(xintercept=as.Date('2020-03-13'))+
  geom_vline(xintercept=as.Date('2020-03-23'))+
  scale_color_OkabeIto()+
  scale_fill_OkabeIto()+
  facet_wrap(timeframe~., ncol=1)+
  theme_minimal() +
  coord_cartesian(ylim=c(0,1))
plot(p)

ggsave(plot=p, file=paste(path, 'figures/bdsky_sampling.pdf', sep='/'), height=5,width=9)

```

# Compares the sampling probability to the number of sequences compared to the number of positives cases from UW Virology

```{r sampling prob}
sampling_times = read.table(paste(path,'/results/sampling_times.tsv',sep="/"), sep="\t", header=T)

sampling_times$Date = as.Date(sampling_times$Date)
uni_dates = unique(c(sampling_times$Date, positive$date))
for (i in seq(1,length(uni_dates))){
  ind1 = which(sampling_times$Date==uni_dates[[i]])
  ind2 = which(positive$date==uni_dates[[i]])
  count1=0
  count2=0
  if (length(ind1)==1){
    count1=sampling_times[ind1,"number"]
  }
  if (length(ind2)==1){
    count2=positive[ind2,"count"]
  }
  new.dat = data.frame(date=uni_dates[[i]], seq=count1,pcr=count2, ratio=count1/(count1+count2))
  if (i==1){
    test.comp = new.dat
  }else{
    test.comp = rbind(test.comp,new.dat)
  }
}

p.test_comp = ggplot(test.comp) +
  geom_line(aes(x=date,y=ratio)) +
    scale_x_date(limits=c(as.Date('2020-02-15'), max(mrsi$date)))  +
  theme_minimal() + xlab("")+
  ylab("percentage of confirmed cases sequenced")


plot(p.test_comp)

```

```{r prevalence_epiinf}
source(paste(path, 'scripts/plot_Traj.R', sep="/"))
plotTraj(fileNames=list(paste(path, 'out/BD_epi.traj', sep="/")),useCumulativeTrajectories=TRUE)

```


```{r prevalence_coal}
first = T

for (i in seq(1,length(mrsi$filename))){
  time_diff = mrsi[i,"date"]-end_time
  time = seq(0,as.numeric(time_diff),14)
  
  if (!startsWith( as.character(mrsi[i,"filename"]),"multibd")){
    # read in the log file
    t = read.table(paste(path,'/out/', mrsi[i,'filename'], '.log',sep=""), sep="\t", header=T)
    # take a 10% burnin
    t = t[-seq(1,length(t$posterior)/10),]
    
    # get all the prevalence estimates
    average_over=1
    for (j in seq(1,length(time)-average_over,1)){
      method = strsplit(as.character(mrsi[i,'filename']), split="_")[[1]][[2]]
      timeframe = timeframename[as.numeric(strsplit(as.character(mrsi[i,'filename']), split="_")[[1]][[3]])]
      
      name1 = paste('Ne',j,sep="")
      name2 = paste('Ne',j+average_over,sep="")
      
      growth = (t[,name1]-t[,name2])/(time[j+average_over]-time[j])*365
      R = 1+growth/becoming_uninf
      # set all R smaller than 0 to 0
      R[which(R<0.25)]=0.25
      # get the Ne at the mid point for this time interval
      Ne = exp(t[,name1])
      
      # compute the prevalence
      I = (Ne*R*(1+1/k))/generation_time
      
      hpdInt = HPDinterval(as.mcmc(I))
      hpdInt.narrow = HPDinterval(as.mcmc(I), prob=0.5)

      new.dat = data.frame(time=mrsi[i,"date"] - time[j], 
                           I.mean=median(I), I.lower=hpdInt[1,'lower'], I.upper=hpdInt[1,'upper'],
                           I.ll=hpdInt.narrow[1,'lower'], I.uu=hpdInt.narrow[1,'upper'],
                           method = method, timeframe=timeframe)
       if (first){
        prev = new.dat
        first = F
      }else{
        prev = rbind(prev, new.dat)
      }
 
    }
  }
}

levels(prev$method) <- c("correlated Ne's", "uncorrelated Ne's", "correlated Ne trajectories")
prev$method <- factor(prev$method, levels =c("correlated Ne's", "correlated Ne trajectories", "uncorrelated Ne's"))

p = ggplot(prev[which(prev$method=="correlated Ne's" & prev$timeframe==timeframename[[length(timeframename)]]),])+
  geom_ribbon(aes(x=time, ymin=I.lower, ymax=I.upper, fill=timeframe), alpha=0.2)+
  geom_ribbon(aes(x=time, ymin=I.ll, ymax=I.uu, fill=timeframe), alpha=0.4)+
  geom_histogram(data=testing[which(testing$detection=="Positive"),], aes(x=date-reporting_delay,y=count), sta="identity")+
  scale_x_date(limits=c(as.Date('2020-02-01'), max(mrsi$date)))  +
  scale_y_continuous(sec.axis = sec_axis(~ .), name = "Prevalence") +
  theme_minimal() +
  theme(legend.position = "none")  +
  scale_color_manual(name="data source", values=c("#56B4E9"))+
  scale_fill_manual(name="data source", values=c("#56B4E9"))+
  coord_cartesian(ylim=c(1,5000))
plot(p)
ggsave(plot=p, file=paste(path, 'figures/coal_prevalence.png', sep='/'), height=3,width=9)


```
